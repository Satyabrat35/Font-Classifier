{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-cvybfe0mdL",
    "outputId": "c51baf7b-84fa-489c-c1de-c1a970c75701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/satya/anaconda3/lib/python3.10/site-packages (2.19.1)\n",
      "Requirement already satisfied: xxhash in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: packaging in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: filelock in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: multiprocess in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pandas in /Users/satya/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/satya/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/satya/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/satya/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/satya/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/satya/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/satya/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/satya/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/satya/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NIwvtGCwzvEk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3GOmYmU0L6p",
    "outputId": "c145485f-40cb-4c58-f642-bedac618f681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGLbaCa70O0U",
    "outputId": "80aacb0d-1b53-4f92-f12c-c5c0e65cf617"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQ99F3rwSFsr",
    "outputId": "d88edfdc-d96a-445f-b699-82428901169c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I Love Glitter',\n",
       " '.DS_Store',\n",
       " 'Holligate Signature',\n",
       " 'Canterbury',\n",
       " 'AguafinaScript',\n",
       " 'James Fajardo',\n",
       " 'GreatVibes',\n",
       " 'Allura',\n",
       " 'alsscrp',\n",
       " 'OpenSans']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"/Users/satya/Desktop/take-home/FontClassifier/data\"\n",
    "font_classes = os.listdir(img_path)\n",
    "# Ignore .DS_store dir\n",
    "font_classes = font_classes[1:]\n",
    "font_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bpxd5a8nSmYX"
   },
   "outputs": [],
   "source": [
    "width, height = 500, 300\n",
    "\n",
    "# Resize image\n",
    "def processImage(image_path):\n",
    "  orginal_img = cv2.imread(image_path)\n",
    "  # img_data = np.array(orginal_img)\n",
    "\n",
    "  # Upscale or downscale based on dimension\n",
    "  if orginal_img.shape[1] < width or orginal_img.shape[0] < height:\n",
    "    resize_img = cv2.resize(orginal_img, (width, height), interpolation= cv2.INTER_CUBIC)\n",
    "  else:\n",
    "    resize_img = cv2.resize(orginal_img, (width, height), interpolation= cv2.INTER_AREA)\n",
    "\n",
    "  return resize_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TnycOLc1XBTR"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t7rkbzf2SqMn"
   },
   "outputs": [],
   "source": [
    "for font_class in font_classes:\n",
    "  # Get all the font images for specific font\n",
    "  font_dir = os.path.join(img_path, font_class)\n",
    "  \n",
    "  if os.path.isdir(font_dir):  \n",
    "    for image_file in os.listdir(font_dir):\n",
    "        if not image_file.startswith('.'):  \n",
    "            image_path = os.path.join(font_dir, image_file)\n",
    "            if os.path.isfile(image_path):\n",
    "                processed_image = processImage(image_path)\n",
    "                images.append(processed_image)\n",
    "                labels.append(font_class)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "\n",
    "data = {'image': images, 'labels': labels}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "0fhGDUZiSqSU",
    "outputId": "b89a7f96-bcec-4dba-b1ed-dc826c062edc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  labels\n",
       "0     [[[255, 255, 255], [255, 255, 255], [255, 255,...       5\n",
       "1     [[[255, 255, 255], [255, 255, 255], [255, 255,...       5\n",
       "2     [[[255, 255, 255], [255, 255, 255], [255, 255,...       5\n",
       "3     [[[255, 255, 255], [255, 255, 255], [255, 255,...       5\n",
       "4     [[[255, 255, 255], [255, 255, 255], [255, 255,...       5\n",
       "...                                                 ...     ...\n",
       "1609  [[[255, 255, 255], [255, 255, 255], [255, 255,...       7\n",
       "1610  [[[255, 255, 255], [255, 255, 255], [255, 255,...       7\n",
       "1611  [[[255, 255, 255], [255, 255, 255], [255, 255,...       7\n",
       "1612  [[[255, 255, 255], [255, 255, 255], [255, 255,...       7\n",
       "1613  [[[255, 255, 255], [255, 255, 255], [255, 255,...       7\n",
       "\n",
       "[1614 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFjXfdux3kza",
    "outputId": "4b6c6969-b70f-45fb-b39b-bdbc5eb7b9e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 500, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ak_c2jyQe837"
   },
   "outputs": [],
   "source": [
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oTukFMUtgf9Q"
   },
   "outputs": [],
   "source": [
    "# Convert into CxHxW format from HxWxC\n",
    "for index, row in new_df.iterrows():\n",
    "\n",
    "    image_tensor = torch.tensor(row['image'])\n",
    "    image_tensor_permuted = image_tensor.permute(2, 0, 1)\n",
    "\n",
    "    new_df.at[index, 'image'] = image_tensor_permuted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acnStVyzf01a",
    "outputId": "0cf1eed5-9a9d-4f26-ef33-11e60eb399d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eobRHF8TNEj0"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data.iloc[idx]['image']\n",
    "        label = self.data.iloc[idx]['labels']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VgGPUAGgNMYM"
   },
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_Zgm4-O74umI"
   },
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "  def __init__(self, num_classes = 10):\n",
    "    # Random seed for PyTorch\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Inheritance\n",
    "    super(ConvNetwork, self).__init__()\n",
    "    self.layer_1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    self.layer_2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    self.fl = nn.Flatten()\n",
    "    self.layer_fc = nn.Linear(32 * 75 * 125, num_classes)\n",
    "    # self.layer_fc = nn.Linear(16 * 75 * 125, num_classes)\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "  def forward(self, input):\n",
    "    output = self.layer_1(input)\n",
    "    output = self.layer_2(output)\n",
    "    output = self.fl(output)\n",
    "    final = self.layer_fc(output)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uJAHPas55HPb"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = ConvNetwork(10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OpzcfYwv5HU3"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vn44urj0Nt1h"
   },
   "outputs": [],
   "source": [
    "all_data_loader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iSCraUvRqWu0"
   },
   "outputs": [],
   "source": [
    "# Split into train test validation\n",
    "total_size = new_df.shape[0]\n",
    "train_size = int(0.7 * total_size)\n",
    "test_size = int(0.15 * total_size)\n",
    "validation_size = total_size - train_size - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MyReI0rbqWy8"
   },
   "outputs": [],
   "source": [
    "train_set, test_set, validation_set = torch.utils.data.random_split(all_data_loader.dataset, [train_size, test_size, validation_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nx8pnWzPqW1j"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "x-N4VuCk5HXP"
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1KYM9Q35HZN",
    "outputId": "5528c70a-98fe-4911-b297-70ba42f96c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 197.4840, Validation Loss: 8.5515\n",
      "Epoch [2/5], Train Loss: 9.8891, Validation Loss: 3.3822\n",
      "Epoch [3/5], Train Loss: 3.7087, Validation Loss: 1.1341\n",
      "Epoch [4/5], Train Loss: 1.4260, Validation Loss: 1.2852\n",
      "Epoch [5/5], Train Loss: 0.4785, Validation Loss: 1.2080\n"
     ]
    }
   ],
   "source": [
    "steps = new_df.shape[0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "\n",
    "  for image, label in train_loader:\n",
    "    image = image.to(torch.float32)\n",
    "    # print(image.size())\n",
    "    output = model(image)\n",
    "    loss = criterion(output, label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss.item() -> avg loss per batch, so scale the loss\n",
    "    train_loss += loss.item() * image.size(0)\n",
    "\n",
    "  train_loss = train_loss / steps\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for image, label in validation_loader:\n",
    "      image = image.to(torch.float32)\n",
    "      output = model(image)\n",
    "\n",
    "      loss = criterion(output, label)\n",
    "      val_loss += loss.item() * image.size(0)\n",
    "\n",
    "  val_loss = val_loss / steps\n",
    "\n",
    "  print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeoIR9hBpFMc",
    "outputId": "075b0230-028e-4601-e220-cde985ba97fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgAPTVA9VA-e",
    "outputId": "63bb6236-04cc-4788-a9f3-a93bb74acb1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -> 85.53719008264463%\n"
     ]
    }
   ],
   "source": [
    "# Test mode\n",
    "model.eval()\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  correct_pred = 0\n",
    "  total_pred = 0\n",
    "\n",
    "  for image, label in test_loader:\n",
    "    image = image.to(torch.float32)\n",
    "    output = model(image)\n",
    "\n",
    "    values, prediction = torch.max(output.data, 1)\n",
    "    preds.append(prediction)\n",
    "    # Add the batch size to total_pred\n",
    "    total_pred += label.size(0)\n",
    "    correct_pred += (prediction == label).sum().item()\n",
    "\n",
    "  print(f'Accuracy -> {100*correct_pred / total_pred}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkKh9IeByPxg",
    "outputId": "d104efa8-3fae-49e1-8f1a-9e4d3c0498d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([8, 4, 7, 5, 6, 1, 5, 0, 6, 7, 7, 0, 6, 8, 4, 1]),\n",
       " tensor([5, 6, 7, 1, 5, 1, 4, 3, 0, 2, 3, 3, 2, 2, 2, 7]),\n",
       " tensor([5, 7, 0, 2, 4, 5, 5, 1, 7, 6, 1, 3, 4, 2, 0, 4]),\n",
       " tensor([5, 6, 5, 6, 6, 3, 2, 4, 0, 3, 1, 2, 4, 2, 6, 5]),\n",
       " tensor([2, 0, 6, 2, 3, 0, 4, 7, 2, 0, 1, 3, 0, 8, 6, 8]),\n",
       " tensor([7, 2, 8, 7, 2, 4, 0, 2, 5, 7, 6, 8, 1, 5, 2, 5]),\n",
       " tensor([7, 4, 5, 3, 7, 6, 6, 6, 7, 4, 6, 1, 1, 0, 5, 0]),\n",
       " tensor([3, 0, 2, 4, 5, 2, 1, 7, 4, 8, 7, 8, 4, 2, 3, 1]),\n",
       " tensor([7, 0, 5, 7, 8, 6, 3, 1, 6, 3, 8, 0, 7, 4, 3, 4]),\n",
       " tensor([2, 7, 1, 2, 3, 4, 5, 2, 2, 0, 6, 5, 0, 5, 2, 4]),\n",
       " tensor([5, 4, 4, 4, 8, 7, 2, 7, 4, 1, 2, 8, 4, 0, 0, 7]),\n",
       " tensor([8, 0, 6, 4, 3, 1, 8, 5, 0, 4, 2, 0, 7, 2, 8, 6]),\n",
       " tensor([5, 0, 4, 0, 5, 0, 4, 5, 8, 5, 4, 0, 2, 0, 4, 2]),\n",
       " tensor([4, 0, 2, 1, 2, 1, 1, 8, 3, 3, 1, 2, 2, 3, 6, 4]),\n",
       " tensor([1, 8, 7, 3, 8, 1, 1, 0, 3, 7, 2, 8, 2, 6, 7, 8]),\n",
       " tensor([4, 4])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mzuFYmcElB2D"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'model checkpoint/cnnmodelbetter.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
